# ======================================================
# MNIST Dataset Classification using MLP
# ======================================================

# -------------------- IMPORT LIBRARIES --------------------

import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# ======================================================
# 1. DATASET HANDLING
# ======================================================

# Loading MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Display dataset shape
print("Training Data Shape:", x_train.shape)
print("Testing Data Shape:", x_test.shape)

# Reshaping images (28x28 -> 784)
x_train = x_train.reshape(-1, 784)
x_test = x_test.reshape(-1, 784)

# Normalizing pixel values (0-255 -> 0-1)
x_train = x_train / 255.0
x_test = x_test / 255.0

# ======================================================
# 2. MLP MODEL ARCHITECTURE
# ======================================================

model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),   # Hidden Layer
    Dense(10, activation='softmax')                      # Output Layer
])

# Model Summary
model.summary()

# ======================================================
# 3. MODEL COMPILATION
# ======================================================

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ======================================================
# 4. TRAINING THE MODEL
# ======================================================

history = model.fit(
    x_train,
    y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.1
)

# ======================================================
# 5. MODEL EVALUATION
# ======================================================

test_loss, test_accuracy = model.evaluate(x_test, y_test)

print("\nTest Accuracy:", test_accuracy)
print("Test Loss:", test_loss)

# ======================================================
# 6. VISUALIZATION
# ======================================================

# -------- Plot 1: Training vs Validation Accuracy --------
plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'])
plt.show()

# -------- Plot 2: Training vs Validation Loss --------
plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Training vs Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'])
plt.show()

# -------- Plot 3: Loss vs Epoch --------
plt.figure()
plt.plot(history.history['loss'])
plt.title('Loss vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

# ======================================================
# 7. OBSERVATIONS
# ======================================================

print("\nObservation:")
print("The MLP model successfully classifies handwritten digits.")
print("Accuracy increases with epochs and validation accuracy stabilizes.")
print("The model achieves high accuracy without significant overfitting.")

